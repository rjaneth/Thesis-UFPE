<!-- # --- -->
<!-- # title: "APPENDICES" -->
<!-- # appendix: true {#sec-appA} -->
<!-- # numbered: false  # 
<!-- # --- -->

<!-- ```{=latex} -->
<!-- \appendix -->
<!-- ``` -->

# LIMIT BEHAVIOR OF ENTROPY FUNCTIONS {#sec-appendix-A}


##  Limit Behavior of $H\bigl(\mathcal{G}^0_I\bigr)$ as $\alpha \to -\infty$ {#app:A1}

To verify that $H\bigl(\mathcal{G}^0_I(\mu, \alpha, L)\bigr)$ converges to $H\bigl(\Gamma_{\text{SAR}}(L, \mu)\bigr)$ as $\alpha \to -\infty$, we show that the additional terms in $H\bigl(\mathcal{G}^0_I\bigr)$ cancel in the limit.

The Shannon entropy for the $\mathcal{G}^0_I$ distribution is given by:
\begin{multline}
\label{eq:GIO-Sh}
H\bigl(\mathcal{G}^0_I(\mu, \alpha, L)\bigr) =H(\Gamma_{\text{SAR}}) +
\Bigl[ (L-\alpha) \psi^{(0)}(L-\alpha)-(1-\alpha)\psi^{(0)}(-\alpha)
+\ln (-1-\alpha) -\ln\Gamma(L-\alpha)\\ +\ln\Gamma(-\alpha)-L\Bigr].
\end{multline}
We aim to show that
$$
\lim_{\alpha \to -\infty} H\bigl(\mathcal{G}^0_I(\mu, \alpha, L)\bigr) = H\bigl(\Gamma_{\text{SAR}}(L, \mu)\bigr).
$$ 
The additional terms in $H\bigl(\mathcal{G}^0_I\bigr)$ compared to $H\bigl(\Gamma_{\text{SAR}}\bigr)$ are:
\begin{multline}
\label{E:lim1}
\lim_{\alpha\to-\infty} \left[ (L-\alpha) \psi^{(0)}(L-\alpha)-(1-\alpha)\psi^{(0)}(-\alpha)
+\ln (-1-\alpha) -\ln\Gamma(L-\alpha) +\ln\Gamma(-\alpha) \right]- L.
\end{multline}
For $L=1$, this becomes:
\begin{align}
\label{E:lim}
\lim_{\alpha\to-\infty} \bigg[\underbrace{-\ln\Gamma(1-\alpha) +\ln (-1-\alpha)+\ln\Gamma(-\alpha)}_{A} + \underbrace{(1-\alpha) \psi^{(0)}(1-\alpha)-(1-\alpha)\psi^{(0)}(-\alpha)}_{B}\bigg]-1.
\end{align}
Simplifying $A$ and $B$:
\begin{align*}
A &= \ln\frac{(-1-\alpha)\Gamma(-\alpha)}{\Gamma(1-\alpha)} = \ln\frac{(-1-\alpha)\Gamma(-\alpha)}{-\alpha\Gamma(-\alpha)} = \ln\frac{-1-\alpha}{-\alpha} = \ln\Big(1+\frac{1}{\alpha}\Big). \\
\end{align*}
\begin{align*}
B &= (1-\alpha)\left[\psi^{(0)}(1-\alpha)-\psi^{(0)}(-\alpha)\right] \\
&= (1-\alpha)\Bigg[\psi^{(0)}\underbrace{(1-\alpha-1)+\frac{1}{1-\alpha-1}}_{\text{Because } \psi^{(0)}(x+1)=\psi^{(0)}(x)+\frac{1}{x}}-\psi^{(0)}(-\alpha)\Bigg] \\
&= (1-\alpha)\left[\psi^{(0)}(-\alpha)-\frac{1}{\alpha}-\psi^{(0)}(-\alpha)\right] = -\frac{1}{\alpha}+1.
\end{align*}
Replacing $A$ and $B$ into \eqref{E:lim} and taking the limit, we obtain:
\begin{align*}
\underbrace{\lim_{\alpha\to-\infty}\ln\left(1+\frac{1}{\alpha}\right)}_{\text{approaches } 0}
-\underbrace{\lim_{\alpha\to-\infty}\frac{1}{\alpha}}_{\text{approaches } 0}
+\lim_{\alpha\to-\infty}1 - 1 = 0.
\end{align*}
For the general case $L > 1$, we use Stirling's approximation for large $z$:
$$
\Gamma(z) \sim \sqrt{2\pi z} \left(\frac{z}{e}\right)^z,
$$
and
$$
\psi^{(0)}(z) \sim \ln(z) - \frac{1}{2z}.
$$

Therefore, the terms of Equation \eqref{E:lim1} approximate to:
\begin{align*}
-\ln\Gamma(L-\alpha) &\sim -\frac{1}{2}\ln\left(2\pi(L-\alpha)\right)-(L-\alpha)\ln(L-\alpha)+(L-\alpha), \\
(L-\alpha) \psi^{(0)}(L-\alpha) &\sim (L-\alpha) \ln(L-\alpha) - \frac{1}{2}, \\
-(1-\alpha) \psi^{(0)}(-\alpha) &\sim -(1-\alpha) \ln(-\alpha) - \frac{1-\alpha}{2\alpha}, \\
\ln\Gamma(-\alpha) &\sim \frac{1}{2}\ln(-2\pi\alpha)-\alpha\ln(-\alpha)+\alpha.
\end{align*}
Then, replacing these in \eqref{E:lim1}, we get:
\begin{multline*}
\lim_{\alpha\to-\infty} \bigg[ -\frac{1}{2}\ln\left(2\pi(L-\alpha)\right)-L\ln(L-\alpha)+\alpha\ln(L-\alpha)+L-\alpha \\
+ L\ln(L-\alpha) -\alpha\ln(L-\alpha) - \frac{1}{2} -\ln(-\alpha)+\alpha\ln(-\alpha) - \frac{1-\alpha}{2\alpha} \\
+ \ln (-1-\alpha)+ \frac{1}{2}\ln(-2\pi\alpha)-\alpha\ln(-\alpha)+\alpha \bigg] - L.
\end{multline*}
We then simplify:
\begin{multline*}
\lim_{\alpha\to-\infty} \bigg[ -\frac{1}{2}\ln(2\pi(L-\alpha)) + L - \frac{1}{2} - \ln(-\alpha) - \frac{1-\alpha}{2\alpha}
+ \ln (-(1+\alpha)) + \frac{1}{2}\ln(-2\pi\alpha) \bigg] - L.
\end{multline*}
Group terms:
$$
\lim_{\alpha\to-\infty} \left[ \frac{1}{2}\ln\frac{-\alpha}{L-\alpha} + L - \frac{1}{2} + \frac{\alpha-1}{2\alpha} + \ln\frac{1+\alpha}{\alpha} \right] - L = \frac{1}{2}\ln 1 + L-\frac{1}{2}+\frac{1}{2}+\ln 1 -L=0.
$$

Therefore,
$$
\lim_{\alpha \to -\infty} H\bigl(\mathcal{G}^0_I(\mu, \alpha, L)\bigr) = H\bigl(\Gamma_{\text{SAR}}(L, \mu)\bigr).
$$ 
which concludes the proof.



## Limit Behavior of \texorpdfstring{$R_\lambda(\mathcal{G}^0_I)$}{Hl(GI0)} as \texorpdfstring{$\alpha \to -\infty$}{alpha->-∞} {#app:A24}


We want to show that 
$$
\lim_{\alpha \to -\infty}
R_\lambda\bigl(\mathcal{G}^0_I\bigr)(\mu, \alpha, L)
=
R_\lambda\bigl(\Gamma_{\mathrm{SAR}}\bigr)(\mu, L).
$$

We can express \eqref{eq-HGI0-R} as follows:
\begin{align*}
R_\lambda\bigl(\mathcal{G}^0_I\bigr)(\mu,\alpha,L)
&=
R_\lambda\bigl(\Gamma_{\mathrm{SAR}}\bigr)(\mu,L)
\;+\;
\ln\!\bigl(-1-\alpha\bigr)
\\
&\quad
+ \frac{1}{1-\lambda}
\ln \Biggl[
  \frac{
    \Gamma(L-\alpha)^{\lambda}\,\Gamma\bigl(\lambda(-\alpha+1)-1\bigr)\,\lambda^{\lambda(L-1)+1}
  }{
    \Gamma(-\alpha)^{\lambda}\,\Gamma\bigl(\lambda(L-\alpha)\bigr)
  }
\Biggr].
\end{align*}
Set
\begin{align*}
\Delta_\alpha
&=
R_\lambda\bigl(\mathcal{G}^0_I\bigr)(\mu,\alpha,L)
-
R_\lambda\bigl(\Gamma_{\mathrm{SAR}}\bigr)(\mu,L).
\end{align*}
Then 
\begin{align}
\Delta_\alpha
=
\ln(-1-\alpha)
+
\frac{1}{1-\lambda}
\ln \biggl[
  \frac{
    \Gamma(L-\alpha)^{\lambda}\,\Gamma\bigl(\lambda(-\alpha+1)-1\bigr)\,\lambda^{\lambda(L-1)+1}
  }{
    \Gamma(-\alpha)^{\lambda}\,\Gamma\bigl(\lambda(L-\alpha)\bigr)
  }
\biggr].
\label{eq:remain}
\end{align}

As $\alpha \to -\infty$, we have $-1-\alpha \approx |\alpha|$, so 
$$
\ln(-1-\alpha) 
\sim 
\ln|\alpha|.
$$
Note that for large $|\alpha|$, we can the asymptotic relation 
$\Gamma(x+a)/\Gamma(x+b)\sim x^{\,a-b}$.
Specifically:
$$
\Gamma(L-\alpha)/\Gamma(-\alpha) \;\sim\; |\alpha|^L,
\quad
\Gamma\bigl(\lambda(-\alpha+1)-1\bigr)/\Gamma\bigl(\lambda(L-\alpha)\bigr)
\;\sim\; 
\bigl(\lambda|\alpha|\bigr)^{\,(\lambda-1)-\lambda L}.
$$
Thus, inside the logarithm in \eqref{eq:remain},
$$
\frac{
  \Gamma(L-\alpha)^{\lambda}\,\Gamma\bigl(\lambda(-\alpha+1)-1\bigr)
}{
  \Gamma(-\alpha)^{\lambda}\,\Gamma\bigl(\lambda(L-\alpha)\bigr)
}
\;\sim\;
|\alpha|^{\lambda L}
\times
|\alpha|^{(\lambda-1)-\lambda L}
=
|\alpha|^{\,\lambda-1}.
$$
Since $\lambda^{\lambda(L-1)+1}$  does not depend on $\alpha$, multiplying by this constant factor does not alter the asymptotic behavior in $\alpha$. Therefore,
$$
\frac{1}{1-\lambda}\,
\ln\!\Bigl[\dots\Bigr]
\;\sim\;
\frac{1}{1-\lambda}\;\ln\!\bigl(|\alpha|^{\,\lambda-1}\bigr)
=
\frac{\lambda-1}{1-\lambda}\,\ln|\alpha|
=
-\ln|\alpha|.
$$
Hence
$$
\Delta_\alpha
\;\sim\;
\ln|\alpha|
-
\ln|\alpha|
=
0
\quad
\text{as}\, \alpha\to -\infty.
$$
This shows 
$\Delta(\alpha)\to 0$, 
and consequently
$$
\lim_{\alpha \to -\infty}
R_\lambda\bigl(\mathcal{G}^0_I\bigr)(\mu,\alpha,L)
=
R_\lambda\bigl(\Gamma_{\mathrm{SAR}}\bigr)(\mu,L).
$$



## Limit Behavior of \texorpdfstring{$T_\lambda(\mathcal{G}^0_I)$}{Hl(GI0)} as \texorpdfstring{$\alpha \to -\infty$}{alpha->-∞} {#app:A33}

We want to show that 
$$
\lim_{\alpha \to -\infty}
T_\lambda\bigl(\mathcal{G}^0_I\bigr)(\mu, \alpha, L)
=
T_\lambda\bigl(\Gamma_{\mathrm{SAR}}\bigr)(\mu, L).
$$
Write the Tsallis entropy of $\mathcal{G}^0_I$ in the compact form  
$$
T_\lambda\!\bigl(\mathcal{G}^0_I(\mu,\alpha,L)\bigr)
=
T_\lambda\!\bigl(\Gamma_{\mathrm{SAR}}(\mu,L)\bigr)
+
\Delta_\alpha^{T},
\qquad
\Delta_\alpha^{T}=
\frac{C}{\lambda-1}\Bigl(1-e^{\Phi_\alpha}\Bigr),
$$
with the constant (independent of $\alpha$)
$$
C=\exp\!\Bigl[(1-\lambda)\ln\mu+(\lambda-1)\ln L
              +\ln\Gamma\!\bigl(\lambda(L-1)+1\bigr)
              -\lambda\ln\Gamma(L)\Bigr]
$$
and
$$
\Phi_\alpha=
(1-\lambda)\ln(-\alpha-1)
+\lambda\ln\!\frac{\Gamma(L-\alpha)}{\Gamma(-\alpha)}
+\ln\!\frac{\Gamma\bigl(\lambda(1-\alpha)-1\bigr)}
             {\Gamma\bigl(\lambda(L-\alpha)\bigr)}.
$$
If $\Phi_\alpha\to0$ as $\alpha\to-\infty$, then
$\exp[\Phi_\alpha]\to1$ and, therefore, $\Delta_\alpha^{T}\to0$.
Hence the goal reduces to showing $\Phi_\alpha\to0$.

For large $|x|$ and fixed $c$, $\displaystyle\frac{\Gamma(x+c)}{\Gamma(x)}\sim x^{\,c}$.

Set $A:=-\alpha\;(>0)$; then $\alpha\to-\infty$ means $A\to\infty$.
Applying the rule we have
$$
\frac{\Gamma(L+A)}{\Gamma(A)}\sim A^{\,L},
\qquad
\frac{\Gamma(\lambda A+\lambda-1)}{\Gamma(\lambda A+\lambda L)}
\sim (\lambda A)^{\,(\lambda-1)-\lambda L}.
$$
Using $\ln x^c = c\ln x$ and $\ln(\lambda A)=\ln\lambda+\ln A$,
$$
\Phi_\alpha
\sim
(1-\lambda)\ln A
+\lambda L\ln A
+\bigl[\lambda(1-L)-1\bigr]
      \bigl(\ln\lambda+\ln A\bigr).
$$
The coefficient of $\ln A$ is
$$
(1-\lambda)+\lambda L+\lambda(1-L)-1
\,=\,0.
$$
so every logarithm in $A$ disappears.  
The remaining constant is
$\bigl[\lambda-1-\lambda L\bigr]\ln\lambda$. But $\lambda-1-\lambda L = -\bigl[\lambda(L-1)+1\bigr]$, and the opposite factor
$\lambda(L-1)+1$ already appears with the opposite sign inside $C$; therefore this constant term vanishes as well. Consequently $\Phi_\alpha\to0$ and thus $\displaystyle\Delta_\alpha^{T}\longrightarrow 0$.

#  DERIVATIONS OF $m$–SPACING ESTIMATORS  {#app:TsallisSpacing}

This appendix mirrors the derivation given for Vasicek’s estimator of Shannon entropy, and the Tsallis  estimator.

## From Quantile Function to Vasicek Estimator {#app:Vasicek}


The differential entropy of a continuous random variable $Z$ with density $f(z)$ is given by:

$$
H(Z) = - \int_{-\infty}^{\infty} f(z)\ln f(z)\,dz.
$$

We now perform a change of variables using the CDF of $F(z)$ and its inverse, the quantile function $Q(p) = F^{-1}(p)$.

- Let $p = F(z)$ so that $z = Q(p)$.
- Then, using the change of variables:
\vspace{-15pt}
$$
dz = Q'(p)\,dp, \quad \text{and} \quad f(z) = F'(z) = \frac{1}{Q'(p)}.
$$

Substituting into the integral:

$$
\begin{aligned}
H(Z) &= - \int_{-\infty}^{\infty} f(z)\ln f(z)\,dz \\
     &= - \int_0^1 f(Q(p))\ln f(Q(p)) \cdot Q'(p)\,dp \\
     &= - \int_0^1 \ln f(Q(p))\,dp.
\end{aligned}
$$

Now, since $f(Q(p)) = \frac{1}{Q'(p)}$, we get:
$$
\ln f(Q(p)) = -\ln Q'(p),
$$

thus,
\vspace{-15pt}
$$
H(Z) = \int_0^1 \ln Q'(p)\,dp.
$$

 Entropy can be expressed without needing the explicit density $f(z)$. It is sufficient to integrate the logarithm of the derivative of the quantile function over $p \in (0,1)$.

In practice, the quantile function $Q$ is unknown, but we have access to a sample $\{Z_1, \dots, Z_n\}$, whose ordered values are:
$$
Z_{(1)} \le Z_{(2)} \le \cdots \le Z_{(n)}.
$$

Each order statistic $Z_{(i)}$ serves as an empirical quantile:
$$
Z_{(i)} \approx Q\left( \frac{i}{n+1} \right).
$$
To approximate $Q'(p)$ at $p_i \approx \frac{i}{n+1}$, we use a symmetric finite difference:
$$
\begin{aligned}
Q'(p_i) &\approx \frac{Q(p_{i+m}) - Q(p_{i-m})}{p_{i+m} - p_{i-m}} \\
&= \frac{Z_{(i+m)} - Z_{(i-m)}}{\frac{i+m}{n+1} - \frac{i-m}{n+1}} \\
&= \frac{n+1}{2m}(Z_{(i+m)} - Z_{(i-m)}).
\end{aligned}
$$

This is a symmetric window of width $2m$, valid for $m < i < n - m$.

<!-- ###  Approximating the Integral as a Discrete Average {.unnumbered} -->

The integral over $p \in [0,1]$ is approximated by a Riemann sum:
$$
\int_0^1 \ln Q'(p)\,dp \approx \frac{1}{n} \sum_{i=1}^{n} \ln Q'(p_i).
$$

Substituting the approximation of $Q'(p_i)$:
$$
\widehat{H}_{\text{V}}(\bm{Z}) = \frac{1}{n} \sum_{i=1}^{n} \ln\left[ \frac{n+1}{2m} \left(Z_{(i+m)} - Z_{(i-m)} \right) \right].
$$

This is the Vasicek estimator of Shannon entropy.



## Tsallis Entropy and the Quantile Function  {#app:tsallis_1} 

For a continuous random variable $Z$ with pdf $f$ and CDF $F$, the Tsallis entropy is  defined by:
$$
  T_\lambda(Z)
  \;=\;
  \frac{1}{\lambda-1}
  \Bigl(
    1 - \mathbb{E}\bigl[f^{\,\lambda-1}(Z)\bigr]
  \Bigr)
  \;=\;
  \frac{1}{\lambda-1}
  \Bigl(
    1 - \textstyle\int_{\mathbb R} f^{\lambda}(z)\,dz
  \Bigr).
  \tag{A.1}
$$
To express $T_\lambda$ in terms of the quantile function
$Q(p)=F^{-1}(p)$ for $p\in(0,1)$, note that
$F\!\bigl(Q(p)\bigr)=p$.
Differentiating with respect to $p$ yields:
\begin{equation}
  f\!\bigl(Q(p)\bigr)\,Q'(p)=1
  \quad\Longrightarrow\quad
  Q'(p)=\frac{1}{f\!\bigl(Q(p)\bigr)}.
  \tag{A.2}
\end{equation}
Using the change of variables $z=Q(p)$ ($dz = Q'(p)\,dp$) in
the integral of (A.1) and applying (A.2),
$$
  \mathbb{E}\bigl[f^{\,\lambda-1}(Z)\bigr]
  \;=\;
  \int_0^1
    \bigl[f(Q(p))\bigr]^{\lambda-1}\,dp
  \;=\;
  \int_0^1
    \bigl[Q'(p)\bigr]^{1-\lambda}\,dp.
$$
Hence the entropy can be written solely in terms of the quantile
derivative:
\begin{equation}
  T_\lambda(Z)
  \;=\;
  \frac{1}{\lambda-1}
  \Bigl\{
     1-\displaystyle\int_0^1
       \bigl[Q'(p)\bigr]^{1-\lambda}\,dp
  \Bigr\}.
  \tag{A.3}
\end{equation}

Equation (A.3) dispenses with the pdf itself, once we can estimate $Q'(p)$, we obtain an estimator of
$T_\lambda$.

Draw an i.i.d.\ sample $Z_1,\dots,Z_n\sim F$ and sort it,
$Z_{(1)}\le\cdots\le Z_{(n)}$.
Fix an integer window
$m\in\{1,\dots,\lfloor n/2\rfloor\}$.
For every index $i=1,\dots,n$ define the (centred)
\emph{$m$–spacing}
$$
  D_{i,m}
  \;=\;
  Z_{(i+m)}-Z_{(i-m)},
$$
with the conventions $Z_{(i-m)}:=Z_{(1)}$ when $i\le m$
and $Z_{(i+m)}:=Z_{(n)}$ when $i\ge n-m$.

Because $Z_{(i)}\approx Q\!\bigl(i/n\bigr)$, the points
$Z_{(i-m)}$ and $Z_{(i+m)}$ correspond roughly to the
probabilities $(i-m)/n$ and $(i+m)/n$, so that\,
$\Delta p = 2m/n$.
A centred finite–difference therefore gives the
\emph{quantile-slope estimator}
$$
  \widehat{Q'}\!\bigl(p_i\bigr)
  \;=\;
  \frac{Z_{(i+m)}-Z_{(i-m)}}{\displaystyle\frac{2m}{n}}
  =\frac{n}{2m}\,D_{i,m},
  \qquad p_i:=\frac{i}{n}.
  \tag{A.4}
$$

To reduce edge bias Ebrahimi et al.&nbsp;[-@Ebrahimi1994]
suggest position-dependent correction factors
$$
  c_i=
  \begin{cases}
    1+\dfrac{i-1}{m}, & 1\le i\le m,\\[6pt]
    2,                & m+1\le i\le n-m,\\[6pt]
    1+\dfrac{n-i}{m}, & n-m+1\le i\le n.
  \end{cases}
  \tag{A.5}
$$
The resulting boundary-corrected $m$-spacing
density estimator is
\begin{equation}
  \widehat f_n\bigl(Z_{(i)}\bigr)
  \;=\;
  \frac{c_i\,m/n}{D_{i,m}},
  \qquad i=1,\dots,n.
  \tag{A.6}
\end{equation}
By construction
$\widehat f_n\bigl(Z_{(i)}\bigr)\approx f\!\bigl(Z_{(i)}\bigr)$,
while its reciprocal gives an improved estimate of $Q'(p_i)$:
\begin{equation}
  \widehat{Q'}\!\bigl(p_i\bigr)
  \;=\;
  \frac{1}{\widehat f_n\bigl(Z_{(i)}\bigr)}
  \;=\;
  \frac{D_{i,m}}{c_i\,m/n}.
  \tag{A.7}
\end{equation}
Approximating the integral in (A.3) by the
Riemann sum over the grid $p_i=i/n$ and inserting $\widehat{Q'}\!\bigl(p_i\bigr)$
of (A.7) yields the non-parametric Tsallis entropy estimator:
$$
  \widehat T_{\lambda}(\bm{Z})
  \;=\;
  \frac{1}{\lambda-1}
  \Biggl\{
     1
     -\frac{1}{n}
      \sum_{i=1}^{n}
      \Bigl[
         \widehat{Q'}\!\bigl(p_i\bigr)
      \Bigr]^{1-\lambda}
  \Biggr\}
  \;=\;
  \frac{1}{\lambda-1}
  \Biggl\{
     1
     -\frac{1}{n}
      \sum_{i=1}^{n}
      \Bigl(
        \frac{c_i\,m/n}{D_{i,m}}
      \Bigr)^{\lambda-1}
  \Biggr\}.
  \tag{A.8}
$$







